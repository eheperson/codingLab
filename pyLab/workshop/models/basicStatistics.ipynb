{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Statistics Libraries\n",
    "\n",
    "### statistics\n",
    "- Python‚Äôs statistics is a built-in Python library for descriptive statistics. You can use it if your datasets are not too large or if you can‚Äôt rely on importing other libraries.\n",
    "\n",
    "### Numpy\n",
    "- NumPy is a third-party library for numerical computing, optimized for working with single- and multi-dimensional arrays. Its primary type is the array type called ndarray. This library contains many routines for statistical analysis.\n",
    "\n",
    "### SciPy\n",
    "- SciPy is a third-party library for scientific computing based on NumPy. It offers additional functionality compared to NumPy, including scipy.stats for statistical analysis.\n",
    "\n",
    "### Pandas\n",
    "- Pandas is a third-party library for numerical computing based on NumPy. It excels in handling labeled one-dimensional (1D) data with Series objects and two-dimensional (2D) data with DataFrame objects.\n",
    "\n",
    "### Matplotlib\n",
    "- Matplotlib is a third-party library for data visualization. It works well in combination with NumPy, SciPy, and Pandas.\n",
    "\n",
    "#### Outliers :\n",
    "An outlier is a data point that differs significantly from the majority of the data taken from a sample or population. There are many possible causes of outliers, but here are a few to start you off:\n",
    "\n",
    "- Natural variation in data\n",
    "- Change in the behavior of the observed system\n",
    "- Errors in data collection\n",
    "\n",
    "\n",
    "### Note that you should always be aware of whether you‚Äôre working with a sample or the entire population whenever you‚Äôre calculating the variance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  [8.0, 1, 2.5, 4, 28.0]\n",
      "\n",
      "\n",
      "X with NaN value :  [8.0, 1, 2.5, nan, 4, 28.0]\n"
     ]
    }
   ],
   "source": [
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "xWithNan = [8.0, 1, 2.5, math.nan, 4, 28.0]\n",
    "print(\"X : \",x)\n",
    "print(\"\\n\")\n",
    "print(\"X with NaN value : \",xWithNan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y :  [ 8.   1.   2.5  4.  28. ]\n",
      "\n",
      "\n",
      "Y with NaN value :  [ 8.   1.   2.5  nan  4.  28. ]\n",
      "\n",
      "\n",
      "Z : \n",
      " 0     8.0\n",
      "1     1.0\n",
      "2     2.5\n",
      "3     4.0\n",
      "4    28.0\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Z with NaN value :\n",
      " 0     8.0\n",
      "1     1.0\n",
      "2     2.5\n",
      "3     NaN\n",
      "4     4.0\n",
      "5    28.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y = np.array(x)\n",
    "yWithNan = np.array(xWithNan)\n",
    "z = pd.Series(x)\n",
    "zWithNan = pd.Series(xWithNan)\n",
    "print(\"Y : \",y)\n",
    "print(\"\\n\")\n",
    "print(\"Y with NaN value : \",yWithNan)\n",
    "print(\"\\n\")\n",
    "print(\"Z : \\n\",z)\n",
    "print(\"\\n\")\n",
    "print(\"Z with NaN value :\\n\",zWithNan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# How do you get a nan value?\n",
    "print(math.isnan(np.nan))\n",
    "print(np.isnan(math.nan))\n",
    "print(math.isnan(yWithNan[3]))\n",
    "print(np.isnan(yWithNan[3]))\n",
    "print(math.isnan(yWithNan[2]))\n",
    "print(np.isnan(yWithNan[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Central Tendency\n",
    "The measures of central tendency show the central or middle values of datasets. There are several definitions of what‚Äôs considered to be the center of a dataset. In this tutorial, you‚Äôll learn how to identify and calculate these measures of central tendency:\n",
    "\n",
    "- Aritmetic mean (Mean)\n",
    "- Weighted mean\n",
    "- Geometric mean\n",
    "- Harmonic mean\n",
    "- Median\n",
    "- Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic mean (AM)\n",
    "\n",
    "- The arithmetic mean (or simply mean) of a list of numbers, is the sum of all of the numbers divided by the amount of numbers. \n",
    "\n",
    "<img src=\"images/arithmeticMean.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Calculation Without Library :  11.622222222222222\n",
      "Mean Calculation With 'statistics.mean' :  11.622222222222222\n",
      "Mean Calculation With 'statistics.fmean' :  11.622222222222222\n",
      "Mean Calculation With 'numpy.mean' :  11.622222222222222\n",
      "Mean Calculation, 'nan' value inclued:  nan\n",
      "Mean Calculation, 'nan' value inclued:  nan\n",
      "Mean Calculation With 'nan' value inclued :  nan\n",
      "Mean Calculation With 'nan' value inclued :  11.622222222222222\n",
      "Mean Calculation With 'pandas.mean' :  11.622222222222222\n",
      "Mean Calculation With 'nan' value inclued :  11.622222222222222\n"
     ]
    }
   ],
   "source": [
    "mean_ = sum(x) / len(x)\n",
    "print(\"Mean Calculation Without Library : \", mean_)\n",
    "\n",
    "# mean() and fmean() from the built-in Python statistics library\n",
    "# fmean() is introduced in Python 3.8 as a faster alternative to mean(). \n",
    "# It always returns a floating-point number.\n",
    "\n",
    "mean_ = statistics.mean(x)\n",
    "print(\"Mean Calculation With 'statistics.mean' : \", mean_)\n",
    "\n",
    "mean_ = statistics.fmean(x)\n",
    "print(\"Mean Calculation With 'statistics.fmean' : \", mean_)\n",
    "\n",
    "mean_ = np.mean(y)\n",
    "print(\"Mean Calculation With 'numpy.mean' : \", mean_)\n",
    "\n",
    "\n",
    "\n",
    "# However, if there are nan values among your data, then statistics.mean() and statistics.fmean() \n",
    "# will return nan as the output:\n",
    "\n",
    "mean_ = statistics.mean(xWithNan)\n",
    "print(\"Mean Calculation, 'nan' value inclued: \", mean_)\n",
    "\n",
    "mean_ = statistics.fmean(xWithNan)\n",
    "print(\"Mean Calculation, 'nan' value inclued: \", mean_)\n",
    "mean_ = yWithNan.mean()\n",
    "print(\"Mean Calculation With 'nan' value inclued : \", mean_)\n",
    "\n",
    "mean_ = np.nanmean(yWithNan)\n",
    "print(\"Mean Calculation With 'nan' value inclued : \", mean_)\n",
    "\n",
    "# mean calculation with pandas library\n",
    "mean_ = z.mean()\n",
    "print(\"Mean Calculation With 'pandas.mean' : \", mean_)\n",
    "# Pandas ignores nan values by default\n",
    "zWithNan.mean()\n",
    "print(\"Mean Calculation With 'nan' value inclued : \", mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Mean (WM)\n",
    "\n",
    "- The weighted arithmetic mean is similar to an ordinary arithmetic mean (the most common type of average), except that instead of each of the data points contributing equally to the final average, some data points contribute more than others.\n",
    "\n",
    "<img src=\"images/weightedMean.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sum of the weights with 'range()' :  6.95\n",
      "\n",
      "\n",
      " Sum of the weights with 'zip()':  6.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "w = [0.1, 0.2, 0.3, 0.25, 0.15]\n",
    "wmean_ = sum(w[i] * x[i] for i in range(len(x))) / sum(w)\n",
    "print(\" Sum of the weights with 'range()' : \", wmean_)\n",
    "print(\"\\n\")\n",
    "wmean_ = sum(x_ * w_ for (x_, w_) in zip(x, w)) / sum(w)\n",
    "print(\" Sum of the weights with 'zip()': \", wmean_)\n",
    "\n",
    "\n",
    "y, z, w = np.array(x), pd.Series(x), np.array(w)\n",
    "\n",
    "wmean_ = np.average(y, weights=w)\n",
    "wmean_\n",
    "\n",
    "wmean_ = np.average(z, weights=w)\n",
    "wmean_\n",
    "\n",
    "(w * y).sum() / w.sum()\n",
    "\n",
    "\n",
    "w = np.array([0.1, 0.2, 0.3, 0.0, 0.2, 0.1])\n",
    "\n",
    "(w * yWithNan).sum() / w.sum()\n",
    "\n",
    "np.average(yWithNan, weights=w)\n",
    "\n",
    "np.average(zWithNan, weights=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Mean (AM)\n",
    "\n",
    "- The geometric mean is an average that is useful for sets of positive numbers, that are interpreted according to their product (as is the case with rates of growth) and not their sum.\n",
    "\n",
    "<img src=\"images/geometricMean.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.67788567485604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmean = 1\n",
    "for item in x:\n",
    "    gmean *= item\n",
    "\n",
    "gmean **= 1 / len(x)\n",
    "gmean\n",
    "\n",
    "\n",
    "gmean = statistics.geometric_mean(x)\n",
    "gmean\n",
    "\n",
    "gmean = statistics.geometric_mean(xWithNan)\n",
    "gmean\n",
    "\n",
    "scipy.stats.gmean(y)\n",
    "\n",
    "scipy.stats.gmean(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonic Mean (HM)\n",
    "\n",
    "- The harmonic mean is an average which is useful for sets of numbers which are defined in relation to some unit, as in the case of speed (i.e., distance per unit of time).\n",
    "\n",
    "<img src=\"images/harmonicMean.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmean = len(x) / sum(1 / item for item in x)\n",
    "hmean\n",
    "\n",
    "#hmean = statistics.harmonic_mean(x)\n",
    "hmean\n",
    "\n",
    "statistics.harmonic_mean(xWithNan)\n",
    "\n",
    "statistics.harmonic_mean([1, 0, 2])\n",
    "\n",
    "#statistics.harmonic_mean([1, 2, -2])  # Raises StatisticsError\n",
    "\n",
    "#scipy.stats.hmean(y)\n",
    "\n",
    "#scipy.stats.hmean(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median\n",
    "\n",
    "- In statistics and probability theory, a median is a value separating the higher half from the lower half of a data sample, a population or a probability distribution. For a data set, it may be thought of as \"the middle\" value. The basic advantage of the median in describing data compared to the mean (often simply described as the \"average\") is that it is not skewed so much by a small proportion of extremely large or small values, and so it may give a better idea of a \"typical\" value.\n",
    "\n",
    "<img src=\"images/median.png\">\n",
    "\n",
    "- If the number of elements is odd, then there‚Äôs a single middle value, so these functions behave just like median().\n",
    "\n",
    "- If the number of elements is even, then there are two middle values. In this case, median_low() returns the lower and median_high() the higher middle value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_with_nan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-02f4d5743dd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mmedian_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_with_nan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_with_nan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_with_nan' is not defined"
     ]
    }
   ],
   "source": [
    "n = len(x)\n",
    "if n % 2:\n",
    "    median_ = sorted(x)[round(0.5*(n-1))]\n",
    "else:\n",
    "    x_ord, index = sorted(x), round(0.5 * n)\n",
    "    median_ = 0.5 * (x_ord[index-1] + x_ord[index])\n",
    "\n",
    "median_\n",
    "\n",
    "median_ = statistics.median(x)\n",
    "median_\n",
    "\n",
    "median_ = statistics.median(x[:-1])\n",
    "median_\n",
    "\n",
    "median_ = np.median(y)\n",
    "median_\n",
    "\n",
    "median_ = np.median(y[:-1])\n",
    "median_\n",
    "\n",
    "np.nanmedian(y_with_nan)\n",
    "\n",
    "np.nanmedian(y_with_nan[:-1])\n",
    "\n",
    "\n",
    "z.median()\n",
    "\n",
    "z_with_nan.median()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode\n",
    "\n",
    "- The mode is the value that appears most often in a set of data values.[1] If X is a discrete random variable, the mode is the value x (i.e, X = x) at which the probability mass function takes its maximum value. In other words, it is the value that is most likely to be sampled.\n",
    "\n",
    "- Like the statistical mean and median, the mode is a way of expressing, in a (usually) single number, important information about a random variable or a population. The numerical value of the mode is the same as that of the mean and median in a normal distribution, and it may be very different in highly skewed distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = [2, 3, 2, 8, 12]\n",
    "mode_ = max((u.count(item), item) for item in set(u))[1]\n",
    "mode_\n",
    "\n",
    "\n",
    "mode_ = statistics.mode(u)\n",
    "mode_\n",
    "mode_ = statistics.multimode(u)\n",
    "mode_\n",
    "\n",
    "# If there‚Äôs more than one modal value, then mode() raises StatisticsError, \n",
    "# while multimode() returns the list with all modes:\n",
    "# statistics.multimode() is introduced in Python 3.8.\n",
    "v = [12, 15, 12, 15, 21, 15, 12]\n",
    "statistics.mode(v)  # Raises StatisticsError\n",
    "statistics.multimode(v)\n",
    "\n",
    "\n",
    "\n",
    "statistics.mode([2, math.nan, 2])\n",
    "\n",
    "statistics.multimode([2, math.nan, 2])\n",
    "\n",
    "statistics.mode([2, math.nan, 0, math.nan, 5])\n",
    "\n",
    "statistics.multimode([2, math.nan, 0, math.nan, 5])\n",
    "\n",
    "\n",
    "\n",
    "u, v = np.array(u), np.array(v)\n",
    "mode_ = scipy.stats.mode(u)\n",
    "mode_\n",
    "\n",
    "mode_ = scipy.stats.mode(v)\n",
    "mode_\n",
    "\n",
    "\n",
    "#numpy array\n",
    "mode_.mode\n",
    "\n",
    "mode_.count\n",
    "\n",
    "\n",
    "#pandas series\n",
    "u, v, w = pd.Series(u), pd.Series(v), pd.Series([2, 2, math.nan])\n",
    "u.mode()\n",
    "\n",
    "\n",
    "v.mode()\n",
    "\n",
    "\n",
    "\n",
    "w.mode()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of Variability\n",
    "\n",
    "The measures of central tendency aren‚Äôt sufficient to describe data. You‚Äôll also need the measures of variability that quantify the spread of data points. In this section, you‚Äôll learn how to identify and calculate the following variability measures:\n",
    "\n",
    "- Variance\n",
    "- Standard deviation\n",
    "- Skewness\n",
    "- Percentiles\n",
    "- Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "- In probability theory and statistics, variance is the expectation of the squared deviation of a random variable from its mean. Informally, it measures how far a set of numbers is spread out from their average value.\n",
    "\n",
    "<br>\n",
    "\n",
    "- In statistics, Bessel's correction is the use of n ‚àí 1 instead of n in the formula for the sample variance and sample standard deviation,[1] where n is the number of observations in a sample. This method corrects the bias in the estimation of the population variance. It also partially corrects the bias in the estimation of the population standard deviation. However, the correction often increases the mean squared error in these estimations.\n",
    "\n",
    "<img src=\"images/variance.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "- You calculate the population variance similarly to the sample variance. However, you have to use ùëõ in the denominator instead of ùëõ ‚àí 1. In this case, ùëõ is the number of items in the entire population. You can get the population variance similar to the sample variance, with the following differences:\n",
    "\n",
    "1- Replace (n - 1) with n in the pure Python implementation. <br>\n",
    "2- Use statistics.pvariance() instead of statistics.variance(). <br>\n",
    "3- Specify the parameter ddof=0 if you use NumPy or Pandas. In NumPy, you can omit ddof because its default value is 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.19999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(x)\n",
    "mean_ = sum(x) / n\n",
    "var_ = sum((item - mean_)**2 for item in x) / (n - 1)\n",
    "var_\n",
    "\n",
    "\n",
    "var_ = statistics.variance(x)\n",
    "var_\n",
    "\n",
    "\n",
    "statistics.variance(xWithNan)\n",
    "\n",
    "# You can also calculate the sample variance with NumPy. \n",
    "# You should use the function np.var() or the corresponding method .var():\n",
    "var_ = np.var(y, ddof=1)\n",
    "var_\n",
    "\n",
    "\n",
    "# It‚Äôs very important to specify the parameter ddof=1. \n",
    "# That‚Äôs how you set the delta degrees of freedom to 1. \n",
    "# This parameter allows the proper calculation of ùë†¬≤, with (ùëõ ‚àí 1) in the denominator instead of ùëõ.\n",
    "var_ = y.var(ddof=1)\n",
    "var_\n",
    "\n",
    "# If you have nan values in the dataset, then np.var() and .var() will return nan\n",
    "np.var(yWithNan, ddof=1)\n",
    "\n",
    "yWithNan.var(ddof=1)\n",
    "\n",
    "# If you want to skip nan values, then you should use np.nanvar():\n",
    "np.nanvar(yWithNan, ddof=1)\n",
    "\n",
    "\n",
    "# pd.Series objects have the method .var()\n",
    "z.var(ddof=1)\n",
    "\n",
    "zWithNan.var(ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation\n",
    "\n",
    "- In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range.\n",
    "\n",
    "<img src=\"images/std1.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "- The population standard deviation refers to the entire population. It‚Äôs the positive square root of the population variance. \n",
    "\n",
    "<img src=\"images/std2.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.12454774346805"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard deviation with pure Python:\n",
    "std_ = var_ ** 0.5\n",
    "std_\n",
    "\n",
    "# we can use statistics.stdev()\n",
    "std_ = statistics.stdev(x)\n",
    "std_\n",
    "\n",
    "# You can get standard deviation with NumPy  \n",
    "# If there are nan values in the dataset, then they‚Äôll return nan.\n",
    "np.std(y, ddof=1)\n",
    "\n",
    "y.std(ddof=1)\n",
    "\n",
    "np.std(yWithNan, ddof=1)\n",
    "\n",
    "yWithNan.std(ddof=1)\n",
    "\n",
    "\n",
    "# To ignore nan values, you should use np.nanstd().\n",
    "# Don‚Äôt forget to set the delta degrees of freedom to 1!\n",
    "np.nanstd(yWithNan, ddof=1)\n",
    "\n",
    "\n",
    "# pd.Series objects also have the method .std() that skips nan by default\n",
    "# The parameter ddof defaults to 1\n",
    "z.std(ddof=1)\n",
    "\n",
    "zWithNan.std(ddof=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness\n",
    "\n",
    "- In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The skewness value can be positive, zero, negative, or undefined.\n",
    "\n",
    "- The skewness defined like this is called the adjusted Fisher-Pearson standardized moment coefficient\n",
    "\n",
    "<img src=\"images/skewnessGraphs.png\">\n",
    "\n",
    "\n",
    "- The skewness of a random variable X is the third standardized moment , defined as:\n",
    "\n",
    "<img src=\"images/skewness.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9470432273905924"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "n = len(x)\n",
    "mean_ = sum(x) / n\n",
    "var_ = sum((item - mean_)**2 for item in x) / (n - 1)\n",
    "std_ = var_ ** 0.5\n",
    "skew_ = (sum((item - mean_)**3 for item in x)\n",
    "         * n / ((n - 1) * (n - 2) * std_**3))\n",
    "skew_\n",
    "# The skewness is positive, so x has a right-side tail.\n",
    "\n",
    "\n",
    "# You can also calculate the sample skewness with scipy.stats.skew()\n",
    "# The optional parameter nan_policy can take the values 'propagate', 'raise', or 'omit'. \n",
    "# It allows you to control how you‚Äôll handle nan values.\n",
    "y, yWithNan = np.array(x), np.array(xWithNan)\n",
    "scipy.stats.skew(y, bias=False)\n",
    "\n",
    "scipy.stats.skew(yWithNan, bias=False)\n",
    "\n",
    "# Pandas Series objects have the method .skew() that \n",
    "# also returns the skewness of a dataset:\n",
    "# .skew() ignores nan values by default, \n",
    "# because of the default value of the optional parameter skipna.\n",
    "z, zWithNan = pd.Series(x), pd.Series(xWithNan)\n",
    "z.skew()\n",
    "\n",
    "zWithNan.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentiles\n",
    "\n",
    "- A percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations falls. For example, the 20th percentile is the value (or score) below which 20% of the observations may be found. Equivalently, 80% of the observations are found above the 20th percentile.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Each dataset has three quartiles, which are the percentiles that divide the dataset into four parts: \n",
    "\n",
    "#### The first quartile :\n",
    "It is the sample 25th percentile. It divides roughly 25% of the smallest items from the rest of the dataset.\n",
    "\n",
    "#### The second quartile :\n",
    "It is the sample 50th percentile or the median. Approximately 25% of the items lie between the first and second quartiles and another 25% between the second and third quartiles.\n",
    "\n",
    "#### The third quartile :\n",
    "It is the sample 75th percentile. It divides roughly 25% of the largest items from the rest of the dataset.\n",
    "\n",
    "<img src=\"images/percentiles.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25     0.1\n",
       "0.50     8.0\n",
       "0.75    21.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to divide your data into several intervals :\n",
    "# use statistics.quantiles():\n",
    "\n",
    "x = [-5.0, -1.1, 0.1, 2.0, 8.0, 12.8, 21.0, 25.8, 41.0]\n",
    "statistics.quantiles(x, n=2)\n",
    "\n",
    "statistics.quantiles(x, n=4, method='inclusive')\n",
    "\n",
    "# statistics.quantiles() is introduced in Python 3.8.\n",
    "\n",
    "# You can also use np.percentile() \n",
    "# to determine any sample percentile in your dataset. \n",
    "# percentile() takes several arguments. \n",
    "# You have to provide the dataset as the first argument and \n",
    "# the percentile value as the second. \n",
    "\n",
    "# find the 5th and 95th percentiles:\n",
    "y = np.array(x)\n",
    "np.percentile(y, 5)\n",
    "\n",
    "np.percentile(y, 95)\n",
    "\n",
    "\n",
    "np.percentile(y, [25, 50, 75])\n",
    "\n",
    "np.median(y)\n",
    "\n",
    "# If you want to ignore nan values, then use np.nanpercentile() instead\n",
    "yWithNan = np.insert(y, 2, np.nan)\n",
    "yWithNan\n",
    "\n",
    "np.nanpercentile(yWithNan, [25, 50, 75])\n",
    "\n",
    "# NumPy also offers you very similar functionality in quantile() and nanquantile().\n",
    "np.quantile(y, 0.05)\n",
    "\n",
    "np.quantile(y, 0.95)\n",
    "\n",
    "np.quantile(y, [0.25, 0.5, 0.75])\n",
    "\n",
    "np.nanquantile(yWithNan, [0.25, 0.5, 0.75])\n",
    "\n",
    "# pd.Series objects have the method .quantile():\n",
    "# .quantile() also needs you to provide the quantile value as the argument. \n",
    "# This value can be a number between 0 and 1 or a sequence of numbers\n",
    "z, zWithNan = pd.Series(y), pd.Series(yWithNan)\n",
    "z.quantile(0.05)\n",
    "\n",
    "z.quantile(0.95)\n",
    "\n",
    "z.quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "\n",
    "zWithNan.quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranges\n",
    "\n",
    "- In statistics, the range of a set of data is the difference between the largest and smallest values. It can give you a rough idea of how the outcome of the data set will be before you look at it actually [1] Difference here is specific, the range of a set of data is the result of subtracting the smallest value from largest value.\n",
    "\n",
    "<br>\n",
    "\n",
    "- max() and min() from the Python standard library\n",
    "- amax() and amin() from NumPy\n",
    "- nanmax() and nanmin() from NumPy to ignore nan values\n",
    "- .max() and .min() from NumPy\n",
    "- .max() and .min() from Pandas to ignore nan values by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can get the range of data is the difference between the maximum and minimum element  \n",
    "# with the function np.ptp():\n",
    "\n",
    "np.ptp(y)\n",
    "\n",
    "np.ptp(z)\n",
    "\n",
    "np.ptp(yWithNan)\n",
    "\n",
    "np.ptp(zWithNan)\n",
    "\n",
    "# some examples of how you would use these routines\n",
    "np.amax(y) - np.amin(y)\n",
    "\n",
    "np.nanmax(yWithNan) - np.nanmin(yWithNan)\n",
    "\n",
    "y.max() - y.min()\n",
    "\n",
    "z.max() - z.min()\n",
    "\n",
    "zWithNan.max() - zWithNan.min()\n",
    "\n",
    "# The interquartile range is the difference between the first and third quartile. \n",
    "# Once you calculate the quartiles, you can take their difference\n",
    "quartiles = np.quantile(y, [0.25, 0.75])\n",
    "quartiles[1] - quartiles[0]\n",
    "\n",
    "quartiles = z.quantile([0.25, 0.75])\n",
    "quartiles[0.75] - quartiles[0.25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Summary\n",
    "\n",
    "SciPy and Pandas offer useful routines to quickly get descriptive statistics with a single function or method call. You can use scipy.stats.describe() \n",
    "\n",
    "The optional parameter nan_policy can take the values 'propagate' (default), 'raise' (an error), or 'omit'. This parameter allows you to control what‚Äôs happening when there are nan values.\n",
    "\n",
    "describe() returns an object that holds the following descriptive statistics:\n",
    "\n",
    "- nobs: the number of observations or elements in your dataset\n",
    "- minmax: the tuple with the minimum and maximum values of your dataset\n",
    "- mean: the mean of your dataset\n",
    "- variance: the variance of your dataset\n",
    "- skewness: the skewness of your dataset\n",
    "- kurtosis: the kurtosis of your dataset\n",
    "\n",
    "Pandas has similar, if not better, functionality. Series objects have the method .describe()\n",
    "\n",
    "It returns a new Series that holds the following:\n",
    "\n",
    "- count: the number of elements in your dataset\n",
    "- mean: the mean of your dataset\n",
    "- std: the standard deviation of your dataset\n",
    "- min and max: the minimum and maximum values of your dataset\n",
    "- 25%, 50%, and 75%: the quartiles of your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SciPy .describe()\n",
    "result = scipy.stats.describe(y, ddof=1, bias=False)\n",
    "result\n",
    "\n",
    "result.nobs\n",
    "\n",
    "result.minmax[0]  # Min\n",
    "\n",
    "result.minmax[1]  # Max\n",
    "\n",
    "result.mean\n",
    "\n",
    "result.variance\n",
    "\n",
    "result.skewness\n",
    "\n",
    "result.kurtosis\n",
    "\n",
    "# Pandas .describe()\n",
    "\n",
    "result = z.describe()\n",
    "result\n",
    "\n",
    "result['mean']\n",
    "\n",
    "result['std']\n",
    "\n",
    "result['min']\n",
    "\n",
    "result['max']\n",
    "\n",
    "result['25%']\n",
    "\n",
    "result['50%']\n",
    "\n",
    "result['75%']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
